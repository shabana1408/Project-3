{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad982843-78f9-4348-a52e-5fba2554931d",
   "metadata": {},
   "source": [
    "# Project 3 - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adae5ec4-40fa-45cd-9c44-3763336cbfc8",
   "metadata": {},
   "source": [
    "## Business problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b3232e-c974-42f8-bad3-17f3cd1b3f3d",
   "metadata": {},
   "source": [
    "- Produce a MySQL database on movies from a subset of IMDB's publicly available dataset.\n",
    "- Use this database to analyze what makes a movie successful.\n",
    "- Provide recommendations to the stakeholder on how to make a successful movie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ceaea0-b142-4f08-a80f-9abbd30926ff",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0858db4-61ff-4981-b31b-76fb9e95fd62",
   "metadata": {},
   "source": [
    "- Perform a test extraction of movies that started in 2000 or 2001\n",
    "- Each year should be saved as a separate .csv.gz file\n",
    "- Use one function to add the certification (MPGG Rating) to movie.info\n",
    "- Test your function on these 2 movie ids: tt0848228 (\"The Avengers\") and tt0332280 (\"The Notebook\")\n",
    "- The other function will help you append/extend a JSON file with Python\n",
    "- Saved the final results to 2 separate .csv.gz files\n",
    "\n",
    "Exploratory Data Analysis\n",
    "\n",
    "- Load in your csv.gz's of results for each year extracted\n",
    "- Concatenate the data into 1 dataframe for the remainder of the analysis\n",
    "    - How many movies had at least some valid financial information (values > 0 for budget OR revenue)?\n",
    "    - Please exclude any movies with 0's for budget AND revenue from the remaining visualizations.\n",
    "    - How many movies are there in each of the certification categories (G/PG/PG-13/R)?\n",
    "    - What is the average revenue per certification category?\n",
    "    - What is the average budget per certification category?\n",
    "- Save a final merged .csv.gz of all of the tmdb api data called \"tmdb_results_combined.csv.gz\"PI calls\r\n",
    "One code file for EDA\r\n",
    "Submit the link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e81cf41-05c7-4a1f-9858-06fabd92f03c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c17b87-8d56-4b80-8e2f-fabfc3daff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tmdbsimple as tmdb\n",
    "\n",
    "import os, json, math, time\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd3103c-8291-4d26-af89-26b4fb72499b",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd0db78-d644-4f43-bbc8-a64380451cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract all movies\n",
    "all_movies = pd.read_csv(\"Data/title_basics.csv.gz\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0e4a673-eb92-4a12-98cc-6e29e7df4bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter movies for start year 2000 and 2001\n",
    "movies_2000 = all_movies[all_movies['startYear'] == 2000]\n",
    "movies_2001 = all_movies[all_movies['startYear'] == 2001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2b3c004-ad31-40ee-b8a1-fef6e0b30b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save as a separate .csv.gz file\n",
    "movies_2000.to_csv(\"Data/movies_2000.csv.gz\", compression='gzip', index=False)\n",
    "movies_2001.to_csv(\"Data/movies_2001.csv.gz\", compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b582d1-6ff4-4a5a-a1a9-4a68058f171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load API credentials\n",
    "import json\n",
    "with open('/Users/ShPatel/.secret/tmdb_api.json', 'r') as f:\n",
    "    login = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d5e091-3bd7-4ccc-a661-094101a521c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb.API_KEY =  login['api-key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "271b100b-6d79-43fa-ae82-b96a821204a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a function to add certification to movies data\n",
    "def get_movie_with_rating(movie_id):\n",
    "    \"\"\"Adapted from source https://github.com/celiao/tmdbsimple\"\"\"\n",
    "    \n",
    "    ## Get the movie object for the current id\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    \n",
    "    ## Save the .info and .releases dictionaries\n",
    "    info = movie.info()\n",
    "    releases = movie.releases()\n",
    "\n",
    "    ## Loop through countries in releases\n",
    "    for c in releases['countries']:\n",
    "        ## When country abbreviation == US\n",
    "        if c['iso_3166_1'] == 'US':\n",
    "            ## Save a certification key in info with the certification\n",
    "            info['certification'] = c['certification']\n",
    "            break\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13f68297-7528-4ae2-ba2c-6d0314259e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>certification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>/9BBTo63ANSmhC4e6r62OJFuK2GL.jpg</td>\n",
       "      <td>{'id': 86311, 'name': 'The Avengers Collection...</td>\n",
       "      <td>220000000</td>\n",
       "      <td>[{'id': 878, 'name': 'Science Fiction'}, {'id'...</td>\n",
       "      <td>https://www.marvel.com/movies/the-avengers</td>\n",
       "      <td>24428</td>\n",
       "      <td>tt0848228</td>\n",
       "      <td>en</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>...</td>\n",
       "      <td>1518815515</td>\n",
       "      <td>143</td>\n",
       "      <td>[{'english_name': 'English', 'iso_639_1': 'en'...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Some assembly required.</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>False</td>\n",
       "      <td>7.711</td>\n",
       "      <td>29302</td>\n",
       "      <td>PG-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>/qom1SZSENdmHFNZBXbtJAU0WTlC.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>29000000</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 18, ...</td>\n",
       "      <td>http://www.newline.com/properties/notebookthe....</td>\n",
       "      <td>11036</td>\n",
       "      <td>tt0332280</td>\n",
       "      <td>en</td>\n",
       "      <td>The Notebook</td>\n",
       "      <td>...</td>\n",
       "      <td>115603229</td>\n",
       "      <td>123</td>\n",
       "      <td>[{'english_name': 'English', 'iso_639_1': 'en'...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Behind every great love is a great story.</td>\n",
       "      <td>The Notebook</td>\n",
       "      <td>False</td>\n",
       "      <td>7.881</td>\n",
       "      <td>10705</td>\n",
       "      <td>PG-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                     backdrop_path  \\\n",
       "0  False  /9BBTo63ANSmhC4e6r62OJFuK2GL.jpg   \n",
       "1  False  /qom1SZSENdmHFNZBXbtJAU0WTlC.jpg   \n",
       "\n",
       "                               belongs_to_collection     budget  \\\n",
       "0  {'id': 86311, 'name': 'The Avengers Collection...  220000000   \n",
       "1                                               None   29000000   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 878, 'name': 'Science Fiction'}, {'id'...   \n",
       "1  [{'id': 10749, 'name': 'Romance'}, {'id': 18, ...   \n",
       "\n",
       "                                            homepage     id    imdb_id  \\\n",
       "0         https://www.marvel.com/movies/the-avengers  24428  tt0848228   \n",
       "1  http://www.newline.com/properties/notebookthe....  11036  tt0332280   \n",
       "\n",
       "  original_language original_title  ...     revenue  runtime  \\\n",
       "0                en   The Avengers  ...  1518815515      143   \n",
       "1                en   The Notebook  ...   115603229      123   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0  [{'english_name': 'English', 'iso_639_1': 'en'...  Released   \n",
       "1  [{'english_name': 'English', 'iso_639_1': 'en'...  Released   \n",
       "\n",
       "                                     tagline         title  video  \\\n",
       "0                    Some assembly required.  The Avengers  False   \n",
       "1  Behind every great love is a great story.  The Notebook  False   \n",
       "\n",
       "   vote_average vote_count certification  \n",
       "0         7.711      29302         PG-13  \n",
       "1         7.881      10705         PG-13  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing our function by looping through a list of ids\n",
    "test_ids = [\"tt0848228\", \"tt0332280\"]\n",
    "results = []\n",
    "errors = []\n",
    "\n",
    "for movie_id in test_ids:\n",
    "    \n",
    "    try:\n",
    "        movie_info = get_movie_with_rating(movie_id)\n",
    "        results.append(movie_info)\n",
    "        \n",
    "    except Exception as e: \n",
    "        errors.append([movie_id, e])\n",
    "    \n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b2bb79-bcd9-401d-9ec7-a3e7dd27e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a function to extend or append a JSON file with phyton\n",
    "def add_certification_to_movie(data, file_name):\n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(file_name,'r+') as file:\n",
    "       \n",
    "        ## Load existing data\n",
    "        file_data = json.load(file)\n",
    "        \n",
    "        ## Extend or append data\n",
    "        if (type(data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        \n",
    "        ## Sets current position at offset\n",
    "        file.seek(0)\n",
    "        \n",
    "        ## Convert back to json\n",
    "        json.dump(file_data, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cf550d7-1811-4366-b3e0-87884e60d026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf7561fb3f94cb2900209e4c0b09966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Years:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m selected_movies \u001b[38;5;241m=\u001b[39m all_movies[all_movies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstartYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m year]\n\u001b[0;32m     15\u001b[0m movie_ids \u001b[38;5;241m=\u001b[39m selected_movies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtconst\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 17\u001b[0m previous_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m clean_movie_ids \u001b[38;5;241m=\u001b[39m movie_ids[\u001b[38;5;241m~\u001b[39mmovie_ids\u001b[38;5;241m.\u001b[39misin(previous_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdb_id\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m movie_id \u001b[38;5;129;01min\u001b[39;00m tqdm_notebook(clean_movie_ids,\n\u001b[0;32m     21\u001b[0m                               desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMovies from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m                               position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     23\u001b[0m                               leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:757\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m json_reader:\n\u001b[1;32m--> 757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:915\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_lines(data_lines))\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:937\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    935\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 937\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:1064\u001b[0m, in \u001b[0;36mParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_numpy()\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_no_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:1320\u001b[0m, in \u001b[0;36mFrameParser._parse_no_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1317\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1324\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1325\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[0;32m   1326\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1327\u001b[0m     }\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\internals\\construction.py:656\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 656\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m have_series:\n\u001b[0;32m    659\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "## Run for extracted movies\n",
    "\n",
    "folder = 'Data/'\n",
    "years = [2000, 2001]\n",
    "\n",
    "for year in tqdm_notebook(years, desc='Years', position=0):\n",
    "\n",
    "    file_name = f'{folder}movies_{year}_final.json'\n",
    "\n",
    "    if not os.path.exists(file_name):\n",
    "        with open(file_name,'w') as file:\n",
    "            json.dump({'imdb_id':0}, file)\n",
    "    \n",
    "    selected_movies = all_movies[all_movies['startYear'] == year]\n",
    "    movie_ids = selected_movies['tconst']\n",
    "\n",
    "    previous_df = pd.read_json(file_name)\n",
    "    clean_movie_ids = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "\n",
    "    for movie_id in tqdm_notebook(clean_movie_ids,\n",
    "                                  desc=f'Movies from {year}',\n",
    "                                  position=1,\n",
    "                                  leave=True):\n",
    "        try:\n",
    "            movie_info = get_movie_with_rating(movie_id)\n",
    "            add_certification_to_movie(movie_info, f'{folder}movies_{year}_final.json')\n",
    "            time.sleep(0.02)\n",
    "        \n",
    "        except Exception as e:\n",
    "            errors.append((movie_id, e))\n",
    "    \n",
    "    results = pd.read_json(f'{folder}movies_{year}_final.json')\n",
    "    results.to_csv(f'{folder}movies_{year}_final.csv.gz', compression='gzip', index=False)\n",
    "\n",
    "    errors = pd.read_json(f'errors_{year}.json')\n",
    "    errors.to_csv(f'{folder}errors_{year}.csv.gz', compression='gzip', index=False)\n",
    "    print(f\"- Total errors: {len(errors)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
